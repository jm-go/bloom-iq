{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.24.1)\n",
      "Downloading scipy-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary, scipy\n",
      "Successfully installed scipy-1.15.1 torchsummary-1.5.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scipy torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.160.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth-httplib2\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-oauthlib\n",
      "  Downloading google_auth_oauthlib-1.2.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.3.0)\n",
      "Collecting Pillow\n",
      "  Downloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/lib/python3/dist-packages (from google-api-python-client) (0.20.2)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 (from google-api-python-client)\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client)\n",
      "  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client)\n",
      "  Downloading proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Downloading cachetools-5.5.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/lib/python3/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (2.4.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.0)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2022.12.7)\n",
      "Downloading google_api_python_client-2.160.0-py2.py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading google_auth_oauthlib-1.2.1-py2.py3-none-any.whl (24 kB)\n",
      "Downloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.8/210.8 kB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading cachetools-5.5.1-py3-none-any.whl (9.5 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.7/221.7 kB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: uritemplate, pyasn1, protobuf, Pillow, cachetools, rsa, requests-oauthlib, pyasn1-modules, proto-plus, googleapis-common-protos, google-auth, google-auth-oauthlib, google-auth-httplib2, google-api-core, google-api-python-client\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 9.3.0\n",
      "    Uninstalling Pillow-9.3.0:\n",
      "      Successfully uninstalled Pillow-9.3.0\n",
      "Successfully installed Pillow-11.1.0 cachetools-5.5.1 google-api-core-2.24.1 google-api-python-client-2.160.0 google-auth-2.38.0 google-auth-httplib2-0.2.0 google-auth-oauthlib-1.2.1 googleapis-common-protos-1.66.0 proto-plus-1.26.0 protobuf-5.29.3 pyasn1-0.6.1 pyasn1-modules-0.4.1 requests-oauthlib-2.0.0 rsa-4.9 uritemplate-4.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.24.1)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 kB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m143.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 kiwisolver-1.4.8 matplotlib-3.10.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.9/507.9 kB\u001b[0m \u001b[31m505.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.8/346.8 kB\u001b[0m \u001b[31m901.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2025.1 tzdata-2025.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "wZUsLoWYUePu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import MobileNet_V3_Large_Weights\n",
    "from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrigYNzZSjNw"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Lu0EA2LVTt8"
   },
   "source": [
    "**Define Custom Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UNCOMMENT ONLY IF UNZIPPING DATASET ###\n",
    "\n",
    "# import zipfile\n",
    "\n",
    "# with zipfile.ZipFile(\"jpg.zip\", \"r\") as zip_ref:\n",
    "#     zip_ref.extractall(\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 8189\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# folder_path = \"images/jpg\"\n",
    "\n",
    "# # Count all files (excluding subdirectories)\n",
    "# file_count = sum(1 for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file)))\n",
    "\n",
    "# print(f\"Number of files: {file_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "-ZEBsFeRVWBl"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torch\n",
    "import scipy.io\n",
    "\n",
    "class OxfordFlowersDataset(Dataset):\n",
    "    def __init__(self, image_folder, label_file, transform=None):\n",
    "        \"\"\"\n",
    "        :param image_folder: Path to the local folder containing images.\n",
    "        :param label_file: Path to the .mat file containing labels.\n",
    "        :param transform: Transformations to apply to the images.\n",
    "        \"\"\"\n",
    "        self.image_folder = image_folder\n",
    "        self.label_file = label_file\n",
    "        self.transform = transform\n",
    "        self.image_files = self._get_image_files()\n",
    "        self.labels = self._load_labels()\n",
    "\n",
    "    def _get_image_files(self):\n",
    "        \"\"\"Retrieve all image file names from the local folder.\"\"\"\n",
    "        image_files = [f for f in os.listdir(self.image_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        return sorted(image_files)  # Ensure images are loaded in order\n",
    "\n",
    "    def _load_labels(self):\n",
    "        \"\"\"Load labels from a local .mat file.\"\"\"\n",
    "        label_data = scipy.io.loadmat(self.label_file)\n",
    "        image_labels = label_data['labels'].flatten() - 1  # Convert 1-based to 0-based indexing\n",
    "        return torch.tensor(image_labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.image_files[idx]\n",
    "        image_path = os.path.join(self.image_folder, file_name)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        try:\n",
    "            # Open image using PIL\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading image {file_name}: {e}\")\n",
    "            return None, None\n",
    "\n",
    "        # Apply transformations if specified\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYhTYvB0VgDI"
   },
   "source": [
    "## Training Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OuLeo-a4V4bm"
   },
   "source": [
    "Proportion:\n",
    "- 75:25 - train:val\n",
    "- 128 batch size\n",
    "- GPU enabled on RunPod\n",
    "- weight decay\n",
    "- dropout\n",
    "- criterion for label smoothing\n",
    "- learning rate scheduler\n",
    "\n",
    "Transformation:\n",
    "- resize to 224x224\n",
    "- horizonal flip\n",
    "- rotate\n",
    "- vertical flip\n",
    "- affine\n",
    "- perspective\n",
    "- convert to tensor\n",
    "- gaussian blur\n",
    "- random erasing\n",
    "- normalize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Yjv2zhrsVizY"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to match model input\n",
    "    \n",
    "    # Stronger Data Augmentation\n",
    "    transforms.RandomRotation(degrees=40),  # Increased rotation range\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Flip horizontally\n",
    "    transforms.RandomVerticalFlip(p=0.2),  # Flip vertically\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2)),  # Increased translation\n",
    "    transforms.RandomPerspective(distortion_scale=0.3, p=0.5),  # Higher perspective change\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.3, hue=0.2),  # Stronger color jitter\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),  # Adding blur\n",
    "\n",
    "    # Convert to Tensor & Normalize\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Standard normalization\n",
    "])\n",
    "\n",
    "dataset = OxfordFlowersDataset(\n",
    "    image_folder = \"images/jpg\", \n",
    "    label_file = \"imagelabels.mat\",\n",
    "    transform   = transform\n",
    ")\n",
    "\n",
    "# Split dataset into training and validation\n",
    "train_size = int(0.75 * len(dataset))  # 75% train, 25% validation\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Data Loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 8189\n",
      "Number of labels: 8189\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of images: {len(dataset.image_files)}\")\n",
    "print(f\"Number of labels: {len(dataset.labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "qn95GotZWZNm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully moved to: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load MobileNetV3 model\n",
    "model = models.mobilenet_v3_large(pretrained=True)\n",
    "\n",
    "# Modify classifier (Add Dropout before Final Layer)\n",
    "model.classifier[2] = nn.Dropout(p=0.4)  # Added dropout to reduce overfitting\n",
    "model.classifier[3] = nn.Linear(model.classifier[3].in_features, 102)  # Adjust for 102 classes\n",
    "\n",
    "# Define device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Check if the model is on GPU\n",
    "for param in model.parameters():\n",
    "    assert param.device == device, f\"Model parameter is on {param.device}, not {device}!\"\n",
    "\n",
    "print(\"Model successfully moved to:\", device)\n",
    "\n",
    "# Optimizer with Weight Decay for Regularization\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Loss Function with Label Smoothing\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Learning Rate Scheduler (Reduce LR on Plateau)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "ZhOJ7bTpWbyX"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icPz7XfRWehr"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "tfskqI2yWgfV"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
    "    \"\"\"Train the model and return losses, accuracies, and elapsed time.\"\"\"\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_acc = 100. * correct / total\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        val_acc = 100. * correct / total\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        # Adjust learning rate if validation loss stagnates\n",
    "        scheduler.step(val_loss / len(val_loader))\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, \"\n",
    "              f\"Train Acc: {train_accuracies[-1]:.2f}%, Val Loss: {val_losses[-1]:.4f}, \"\n",
    "              f\"Val Acc: {val_accuracies[-1]:.2f}%\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    return model, train_losses, val_losses, train_accuracies, val_accuracies, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_curves(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "    \"\"\"Plot loss and accuracy curves and save them as images.\"\"\"\n",
    "    \n",
    "    # Plot losses\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label='Training Loss', marker='o')\n",
    "    plt.plot(val_losses, label='Validation Loss', marker='s')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Learning Curve: Loss')\n",
    "    plt.savefig(\"loss_curve.png\")  # Save loss curve\n",
    "    plt.close()\n",
    "\n",
    "    # Plot accuracies\n",
    "    plt.figure()\n",
    "    plt.plot(train_accuracies, label='Training Accuracy', marker='o')\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy', marker='s')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.title('Learning Curve: Accuracy')\n",
    "    plt.savefig(\"accuracy_curve.png\")  # Save accuracy curve\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Saved plots as 'loss_curve.png' and 'accuracy_curve.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 2.1006, Train Acc: 49.93%, Val Loss: 3.7218, Val Acc: 29.88%\n",
      "Epoch 2/100, Train Loss: 0.5879, Train Acc: 82.98%, Val Loss: 2.0924, Val Acc: 53.32%\n",
      "Epoch 3/100, Train Loss: 0.3551, Train Acc: 89.29%, Val Loss: 0.9161, Val Acc: 78.17%\n",
      "Epoch 4/100, Train Loss: 0.2763, Train Acc: 91.30%, Val Loss: 0.7101, Val Acc: 82.18%\n",
      "Epoch 5/100, Train Loss: 0.2413, Train Acc: 92.62%, Val Loss: 0.6024, Val Acc: 84.33%\n",
      "Epoch 6/100, Train Loss: 0.1717, Train Acc: 94.61%, Val Loss: 0.5933, Val Acc: 83.89%\n",
      "Epoch 7/100, Train Loss: 0.1686, Train Acc: 94.76%, Val Loss: 0.6290, Val Acc: 84.57%\n",
      "Epoch 8/100, Train Loss: 0.1607, Train Acc: 94.98%, Val Loss: 0.6955, Val Acc: 84.81%\n",
      "Epoch 9/100, Train Loss: 0.1438, Train Acc: 95.54%, Val Loss: 0.4757, Val Acc: 87.89%\n",
      "Epoch 10/100, Train Loss: 0.1265, Train Acc: 96.35%, Val Loss: 0.5340, Val Acc: 86.38%\n",
      "Epoch 11/100, Train Loss: 0.1202, Train Acc: 96.30%, Val Loss: 0.4645, Val Acc: 88.92%\n",
      "Epoch 12/100, Train Loss: 0.1033, Train Acc: 97.00%, Val Loss: 0.3417, Val Acc: 90.67%\n",
      "Epoch 13/100, Train Loss: 0.1041, Train Acc: 96.87%, Val Loss: 0.4088, Val Acc: 89.40%\n",
      "Epoch 14/100, Train Loss: 0.1079, Train Acc: 96.78%, Val Loss: 0.4015, Val Acc: 89.70%\n",
      "Epoch 15/100, Train Loss: 0.1139, Train Acc: 96.61%, Val Loss: 0.5404, Val Acc: 86.67%\n",
      "Epoch 16/100, Train Loss: 0.1051, Train Acc: 96.81%, Val Loss: 0.4210, Val Acc: 89.70%\n",
      "Epoch 17/100, Train Loss: 0.1095, Train Acc: 96.71%, Val Loss: 0.6010, Val Acc: 86.23%\n",
      "Epoch 18/100, Train Loss: 0.0710, Train Acc: 97.87%, Val Loss: 0.4136, Val Acc: 90.28%\n",
      "Epoch 19/100, Train Loss: 0.0769, Train Acc: 97.70%, Val Loss: 0.4851, Val Acc: 88.04%\n",
      "Epoch 20/100, Train Loss: 0.0812, Train Acc: 97.46%, Val Loss: 0.6008, Val Acc: 86.72%\n",
      "Epoch 21/100, Train Loss: 0.0858, Train Acc: 97.46%, Val Loss: 0.3836, Val Acc: 90.82%\n",
      "Epoch 22/100, Train Loss: 0.0637, Train Acc: 97.96%, Val Loss: 0.4179, Val Acc: 89.45%\n",
      "Epoch 23/100, Train Loss: 0.0716, Train Acc: 97.77%, Val Loss: 0.4316, Val Acc: 89.79%\n",
      "Epoch 24/100, Train Loss: 0.0956, Train Acc: 97.36%, Val Loss: 0.6852, Val Acc: 84.86%\n",
      "Epoch 25/100, Train Loss: 0.1004, Train Acc: 96.86%, Val Loss: 0.6136, Val Acc: 87.45%\n",
      "Epoch 26/100, Train Loss: 0.0736, Train Acc: 97.80%, Val Loss: 0.3865, Val Acc: 91.41%\n",
      "Epoch 27/100, Train Loss: 0.0634, Train Acc: 98.09%, Val Loss: 0.3970, Val Acc: 90.58%\n",
      "Epoch 28/100, Train Loss: 0.0640, Train Acc: 97.92%, Val Loss: 0.3978, Val Acc: 89.79%\n",
      "Epoch 29/100, Train Loss: 0.0671, Train Acc: 97.87%, Val Loss: 0.4203, Val Acc: 89.84%\n",
      "Epoch 30/100, Train Loss: 0.0633, Train Acc: 98.19%, Val Loss: 0.4081, Val Acc: 89.79%\n",
      "Epoch 31/100, Train Loss: 0.0517, Train Acc: 98.31%, Val Loss: 0.3390, Val Acc: 91.75%\n",
      "Epoch 32/100, Train Loss: 0.0452, Train Acc: 98.47%, Val Loss: 0.4023, Val Acc: 91.11%\n",
      "Epoch 33/100, Train Loss: 0.0487, Train Acc: 98.57%, Val Loss: 0.4894, Val Acc: 89.06%\n",
      "Epoch 34/100, Train Loss: 0.0658, Train Acc: 98.05%, Val Loss: 0.4543, Val Acc: 89.65%\n",
      "Epoch 35/100, Train Loss: 0.0620, Train Acc: 98.06%, Val Loss: 0.4788, Val Acc: 88.72%\n",
      "Epoch 36/100, Train Loss: 0.0475, Train Acc: 98.84%, Val Loss: 0.3378, Val Acc: 91.80%\n",
      "Epoch 37/100, Train Loss: 0.0439, Train Acc: 98.66%, Val Loss: 0.3639, Val Acc: 91.11%\n",
      "Epoch 38/100, Train Loss: 0.0424, Train Acc: 98.73%, Val Loss: 0.3551, Val Acc: 91.41%\n",
      "Epoch 39/100, Train Loss: 0.0445, Train Acc: 98.70%, Val Loss: 0.4909, Val Acc: 89.55%\n",
      "Epoch 40/100, Train Loss: 0.0700, Train Acc: 97.67%, Val Loss: 0.6730, Val Acc: 86.08%\n",
      "Epoch 41/100, Train Loss: 0.0600, Train Acc: 98.01%, Val Loss: 0.4289, Val Acc: 89.94%\n",
      "Epoch 42/100, Train Loss: 0.0789, Train Acc: 97.57%, Val Loss: 0.4935, Val Acc: 88.82%\n",
      "Epoch 43/100, Train Loss: 0.0765, Train Acc: 97.69%, Val Loss: 0.5174, Val Acc: 86.91%\n",
      "Epoch 44/100, Train Loss: 0.0744, Train Acc: 97.75%, Val Loss: 0.6646, Val Acc: 85.84%\n",
      "Epoch 45/100, Train Loss: 0.0873, Train Acc: 97.64%, Val Loss: 0.5678, Val Acc: 86.52%\n",
      "Epoch 46/100, Train Loss: 0.0881, Train Acc: 97.33%, Val Loss: 0.5060, Val Acc: 88.48%\n",
      "Epoch 47/100, Train Loss: 0.0621, Train Acc: 98.18%, Val Loss: 0.3592, Val Acc: 91.26%\n",
      "Epoch 48/100, Train Loss: 0.0423, Train Acc: 98.96%, Val Loss: 0.3694, Val Acc: 91.85%\n",
      "Epoch 49/100, Train Loss: 0.0326, Train Acc: 98.84%, Val Loss: 0.4285, Val Acc: 91.21%\n",
      "Epoch 50/100, Train Loss: 0.0560, Train Acc: 98.53%, Val Loss: 0.3993, Val Acc: 89.65%\n",
      "Epoch 51/100, Train Loss: 0.0546, Train Acc: 98.32%, Val Loss: 0.4590, Val Acc: 89.50%\n",
      "Epoch 52/100, Train Loss: 0.0611, Train Acc: 98.09%, Val Loss: 0.4753, Val Acc: 89.50%\n",
      "Epoch 53/100, Train Loss: 0.0536, Train Acc: 98.36%, Val Loss: 0.4058, Val Acc: 90.87%\n",
      "Epoch 54/100, Train Loss: 0.0395, Train Acc: 98.73%, Val Loss: 0.3594, Val Acc: 91.94%\n",
      "Epoch 55/100, Train Loss: 0.0470, Train Acc: 98.71%, Val Loss: 0.4833, Val Acc: 88.57%\n",
      "Epoch 56/100, Train Loss: 0.0370, Train Acc: 98.76%, Val Loss: 0.4271, Val Acc: 90.04%\n",
      "Epoch 57/100, Train Loss: 0.0501, Train Acc: 98.32%, Val Loss: 0.4267, Val Acc: 90.43%\n",
      "Epoch 58/100, Train Loss: 0.0511, Train Acc: 98.60%, Val Loss: 0.4606, Val Acc: 90.58%\n",
      "Epoch 59/100, Train Loss: 0.0484, Train Acc: 98.70%, Val Loss: 0.4027, Val Acc: 90.62%\n",
      "Epoch 60/100, Train Loss: 0.0676, Train Acc: 98.13%, Val Loss: 0.5708, Val Acc: 86.87%\n",
      "Epoch 61/100, Train Loss: 0.0521, Train Acc: 98.44%, Val Loss: 0.4714, Val Acc: 89.79%\n",
      "Epoch 62/100, Train Loss: 0.0494, Train Acc: 98.44%, Val Loss: 0.4936, Val Acc: 88.82%\n",
      "Epoch 63/100, Train Loss: 0.0463, Train Acc: 98.60%, Val Loss: 0.4523, Val Acc: 90.43%\n",
      "Epoch 64/100, Train Loss: 0.0381, Train Acc: 98.84%, Val Loss: 0.4199, Val Acc: 90.62%\n",
      "Epoch 65/100, Train Loss: 0.0424, Train Acc: 98.76%, Val Loss: 0.4699, Val Acc: 89.31%\n",
      "Epoch 66/100, Train Loss: 0.0473, Train Acc: 98.55%, Val Loss: 0.3544, Val Acc: 91.02%\n",
      "Epoch 67/100, Train Loss: 0.0436, Train Acc: 98.86%, Val Loss: 0.3473, Val Acc: 92.72%\n",
      "Epoch 68/100, Train Loss: 0.0533, Train Acc: 98.52%, Val Loss: 0.3898, Val Acc: 91.21%\n",
      "Epoch 69/100, Train Loss: 0.0249, Train Acc: 99.28%, Val Loss: 0.3371, Val Acc: 91.89%\n",
      "Epoch 70/100, Train Loss: 0.0392, Train Acc: 98.76%, Val Loss: 0.3424, Val Acc: 91.85%\n",
      "Epoch 71/100, Train Loss: 0.0382, Train Acc: 98.81%, Val Loss: 0.3769, Val Acc: 91.65%\n",
      "Epoch 72/100, Train Loss: 0.0547, Train Acc: 98.45%, Val Loss: 0.4397, Val Acc: 89.65%\n",
      "Epoch 73/100, Train Loss: 0.0592, Train Acc: 98.14%, Val Loss: 0.4606, Val Acc: 89.31%\n",
      "Epoch 74/100, Train Loss: 0.0405, Train Acc: 98.75%, Val Loss: 0.3441, Val Acc: 92.09%\n",
      "Epoch 75/100, Train Loss: 0.0477, Train Acc: 98.55%, Val Loss: 0.5230, Val Acc: 87.79%\n",
      "Epoch 76/100, Train Loss: 0.0619, Train Acc: 98.24%, Val Loss: 0.6449, Val Acc: 86.96%\n",
      "Epoch 77/100, Train Loss: 0.0540, Train Acc: 98.50%, Val Loss: 0.4342, Val Acc: 90.38%\n",
      "Epoch 78/100, Train Loss: 0.0529, Train Acc: 98.57%, Val Loss: 0.4406, Val Acc: 90.04%\n",
      "Epoch 79/100, Train Loss: 0.0394, Train Acc: 98.86%, Val Loss: 0.4418, Val Acc: 89.40%\n",
      "Epoch 80/100, Train Loss: 0.0356, Train Acc: 99.02%, Val Loss: 0.3755, Val Acc: 91.46%\n",
      "Epoch 81/100, Train Loss: 0.0234, Train Acc: 99.28%, Val Loss: 0.2663, Val Acc: 93.75%\n",
      "Epoch 82/100, Train Loss: 0.0260, Train Acc: 99.30%, Val Loss: 0.3318, Val Acc: 92.38%\n",
      "Epoch 83/100, Train Loss: 0.0228, Train Acc: 99.30%, Val Loss: 0.3032, Val Acc: 93.21%\n",
      "Epoch 84/100, Train Loss: 0.0191, Train Acc: 99.53%, Val Loss: 0.3526, Val Acc: 91.85%\n",
      "Epoch 85/100, Train Loss: 0.0254, Train Acc: 99.14%, Val Loss: 0.3659, Val Acc: 93.16%\n",
      "Epoch 86/100, Train Loss: 0.0500, Train Acc: 98.71%, Val Loss: 0.4526, Val Acc: 89.89%\n",
      "Epoch 87/100, Train Loss: 0.0312, Train Acc: 98.96%, Val Loss: 0.4991, Val Acc: 89.84%\n",
      "Epoch 88/100, Train Loss: 0.0538, Train Acc: 98.49%, Val Loss: 0.8340, Val Acc: 85.06%\n",
      "Epoch 89/100, Train Loss: 0.0658, Train Acc: 98.19%, Val Loss: 0.5079, Val Acc: 88.82%\n",
      "Epoch 90/100, Train Loss: 0.0579, Train Acc: 98.31%, Val Loss: 0.4747, Val Acc: 90.09%\n",
      "Epoch 91/100, Train Loss: 0.0582, Train Acc: 98.52%, Val Loss: 0.4170, Val Acc: 90.23%\n",
      "Epoch 92/100, Train Loss: 0.0428, Train Acc: 98.63%, Val Loss: 0.5304, Val Acc: 88.67%\n",
      "Epoch 93/100, Train Loss: 0.0380, Train Acc: 98.86%, Val Loss: 0.3980, Val Acc: 91.46%\n",
      "Epoch 94/100, Train Loss: 0.0346, Train Acc: 98.96%, Val Loss: 0.3184, Val Acc: 92.97%\n",
      "Epoch 95/100, Train Loss: 0.0524, Train Acc: 98.58%, Val Loss: 0.3128, Val Acc: 92.14%\n",
      "Epoch 96/100, Train Loss: 0.0343, Train Acc: 98.91%, Val Loss: 0.5346, Val Acc: 88.62%\n",
      "Epoch 97/100, Train Loss: 0.0476, Train Acc: 98.63%, Val Loss: 0.3568, Val Acc: 92.04%\n",
      "Epoch 98/100, Train Loss: 0.0342, Train Acc: 99.14%, Val Loss: 0.2971, Val Acc: 93.60%\n",
      "Epoch 99/100, Train Loss: 0.0193, Train Acc: 99.32%, Val Loss: 0.2940, Val Acc: 93.95%\n",
      "Epoch 100/100, Train Loss: 0.0238, Train Acc: 99.17%, Val Loss: 0.4931, Val Acc: 90.67%\n",
      "\n",
      "Elapsed time: 2201.08 seconds\n",
      "\n",
      "Saved plots as 'loss_curve.png' and 'accuracy_curve.png'\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model, train_losses, val_losses, train_accuracies, val_accuracies, elapsed_time = train_model(\n",
    "    model, criterion, optimizer, train_loader, val_loader, num_epochs=100\n",
    ")\n",
    "\n",
    "print(f\"\\nElapsed time: {elapsed_time:.2f} seconds\\n\")\n",
    "\n",
    "# Plot and save learning curves\n",
    "plot_and_save_curves(train_losses, val_losses, train_accuracies, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "      <th>Epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best Training Accuracy</td>\n",
       "      <td>99.63%</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Best Validation Accuracy</td>\n",
       "      <td>95.42%</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best Training Loss</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best Validation Loss</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Metric   Value  Epoch\n",
       "0    Best Training Accuracy  99.63%     85\n",
       "1  Best Validation Accuracy  95.42%     82\n",
       "2        Best Training Loss  0.0124     83\n",
       "3      Best Validation Loss  0.2197     75"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Extract best accuracy and corresponding epoch\n",
    "best_train_acc = max(train_accuracies)\n",
    "best_train_acc_epoch = np.argmax(train_accuracies) + 1\n",
    "\n",
    "best_val_acc = max(val_accuracies)\n",
    "best_val_acc_epoch = np.argmax(val_accuracies) + 1\n",
    "\n",
    "# Extract best (lowest) loss and corresponding epoch\n",
    "best_train_loss = min(train_losses)\n",
    "best_train_loss_epoch = np.argmin(train_losses) + 1\n",
    "\n",
    "best_val_loss = min(val_losses)\n",
    "best_val_loss_epoch = np.argmin(val_losses) + 1\n",
    "\n",
    "# Create a summary dictionary\n",
    "best_metrics_summary = {\n",
    "    \"Metric\": [\"Best Training Accuracy\", \"Best Validation Accuracy\", \"Best Training Loss\", \"Best Validation Loss\"],\n",
    "    \"Value\": [f\"{best_train_acc:.2f}%\", f\"{best_val_acc:.2f}%\", f\"{best_train_loss:.4f}\", f\"{best_val_loss:.4f}\"],\n",
    "    \"Epoch\": [best_train_acc_epoch, best_val_acc_epoch, best_train_loss_epoch, best_val_loss_epoch]\n",
    "}\n",
    "\n",
    "# Convert to dataframe and display\n",
    "import pandas as pd\n",
    "best_metrics_df = pd.DataFrame(best_metrics_summary)\n",
    "\n",
    "best_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
