{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.15.1)\n",
      "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.24.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scipy torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.161.0)\n",
      "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (11.1.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/lib/python3/dist-packages (from google-api-python-client) (0.20.2)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.38.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.24.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (2.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.67.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (5.29.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.26.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/lib/python3/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (2.4.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2022.12.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.24.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wZUsLoWYUePu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import MobileNet_V3_Large_Weights\n",
    "from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "from torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrigYNzZSjNw"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Lu0EA2LVTt8"
   },
   "source": [
    "**Define Custom Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UNCOMMENT ONLY IF UNZIPPING DATASET ###\n",
    "\n",
    "# import zipfile\n",
    "\n",
    "# with zipfile.ZipFile(\"jpg.zip\", \"r\") as zip_ref:\n",
    "#     zip_ref.extractall(\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 8189\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# folder_path = \"images/jpg\"\n",
    "\n",
    "# # Count all files (excluding subdirectories)\n",
    "# file_count = sum(1 for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file)))\n",
    "\n",
    "# print(f\"Number of files: {file_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-ZEBsFeRVWBl"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import torch\n",
    "import scipy.io\n",
    "\n",
    "class OxfordFlowersDataset(Dataset):\n",
    "    def __init__(self, image_folder, label_file, transform=None):\n",
    "        \"\"\"\n",
    "        :param image_folder: Path to the local folder containing images.\n",
    "        :param label_file: Path to the .mat file containing labels.\n",
    "        :param transform: Transformations to apply to the images.\n",
    "        \"\"\"\n",
    "        self.image_folder = image_folder\n",
    "        self.label_file = label_file\n",
    "        self.transform = transform\n",
    "        self.image_files = self._get_image_files()\n",
    "        self.labels = self._load_labels()\n",
    "\n",
    "    def _get_image_files(self):\n",
    "        \"\"\"Retrieve all image file names from the local folder.\"\"\"\n",
    "        image_files = [f for f in os.listdir(self.image_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        return sorted(image_files)  # Ensure images are loaded in order\n",
    "\n",
    "    def _load_labels(self):\n",
    "        \"\"\"Load labels from a local .mat file.\"\"\"\n",
    "        label_data = scipy.io.loadmat(self.label_file)\n",
    "        image_labels = label_data['labels'].flatten() - 1  # Convert 1-based to 0-based indexing\n",
    "        return torch.tensor(image_labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.image_files[idx]\n",
    "        image_path = os.path.join(self.image_folder, file_name)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        try:\n",
    "            # Open image using PIL\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading image {file_name}: {e}\")\n",
    "            return None, None\n",
    "\n",
    "        # Apply transformations if specified\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYhTYvB0VgDI"
   },
   "source": [
    "## Training Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OuLeo-a4V4bm"
   },
   "source": [
    "Proportion:\n",
    "- 75:25 - train:val\n",
    "- 128 batch size\n",
    "- GPU enabled on RunPod\n",
    "- weight decay\n",
    "- dropout\n",
    "- criterion for label smoothing\n",
    "- learning rate scheduler (Cosine Annealing Learning Rate Scheduler)\n",
    "\n",
    "Transformation:\n",
    "- resize to 224x224\n",
    "- horizonal flip\n",
    "- rotate\n",
    "- vertical flip\n",
    "- affine\n",
    "- perspective\n",
    "- convert to tensor\n",
    "- gaussian blur\n",
    "- random erasing\n",
    "- normalize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Yjv2zhrsVizY"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to match model input\n",
    "    \n",
    "    # Stronger Data Augmentation\n",
    "    transforms.RandomRotation(degrees=40),  # Increased rotation range\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Flip horizontally\n",
    "    transforms.RandomVerticalFlip(p=0.2),  # Flip vertically\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2)),  # Increased translation\n",
    "    transforms.RandomPerspective(distortion_scale=0.3, p=0.5),  # Higher perspective change\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.3, hue=0.2),  # Stronger color jitter\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),  # Adding blur\n",
    "\n",
    "    # Convert to Tensor & Normalize\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Standard normalization\n",
    "])\n",
    "\n",
    "dataset = OxfordFlowersDataset(\n",
    "    image_folder = \"images/jpg\", \n",
    "    label_file = \"imagelabels.mat\",\n",
    "    transform   = transform\n",
    ")\n",
    "\n",
    "# Split dataset into training and validation\n",
    "train_size = int(0.8 * len(dataset))  # 80% train, 20% validation\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Data Loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 8189\n",
      "Number of labels: 8189\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of images: {len(dataset.image_files)}\")\n",
    "print(f\"Number of labels: {len(dataset.labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "qn95GotZWZNm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully moved to: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load MobileNetV3 model\n",
    "model = mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Modify classifier (Add Dropout before Final Layer)\n",
    "model.classifier[2] = nn.Dropout(p=0.4)  # Added dropout to reduce overfitting\n",
    "model.classifier[3] = nn.Linear(model.classifier[3].in_features, 102)  # Adjust for 102 classes\n",
    "\n",
    "# Define device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Check if the model is on GPU\n",
    "for param in model.parameters():\n",
    "    assert param.device == device, f\"Model parameter is on {param.device}, not {device}!\"\n",
    "\n",
    "print(\"Model successfully moved to:\", device)\n",
    "\n",
    "# Optimizer with Weight Decay for Regularization\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Loss Function with Label Smoothing\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Learning Rate Scheduler (Reduce LR on Plateau)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ZhOJ7bTpWbyX"
   },
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icPz7XfRWehr"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "tfskqI2yWgfV"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
    "    \"\"\"Train the model and return losses, accuracies, and elapsed time.\"\"\"\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_acc = 100. * correct / total\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        val_acc = 100. * correct / total\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        # Adjust learning rate if validation loss stagnates\n",
    "        scheduler.step(val_loss / len(val_loader))\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, \"\n",
    "              f\"Train Acc: {train_accuracies[-1]:.2f}%, Val Loss: {val_losses[-1]:.4f}, \"\n",
    "              f\"Val Acc: {val_accuracies[-1]:.2f}%\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    return model, train_losses, val_losses, train_accuracies, val_accuracies, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_and_save_curves(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "#     \"\"\"Plot loss and accuracy curves and save them as images.\"\"\"\n",
    "    \n",
    "#     # Plot losses\n",
    "#     plt.figure()\n",
    "#     plt.plot(train_losses, label='Training Loss', marker='o')\n",
    "#     plt.plot(val_losses, label='Validation Loss', marker='s')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.legend()\n",
    "#     plt.title('Learning Curve: Loss')\n",
    "#     plt.savefig(\"loss_curve.png\")  # Save loss curve\n",
    "#     plt.close()\n",
    "\n",
    "#     # Plot accuracies\n",
    "#     plt.figure()\n",
    "#     plt.plot(train_accuracies, label='Training Accuracy', marker='o')\n",
    "#     plt.plot(val_accuracies, label='Validation Accuracy', marker='s')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('Accuracy (%)')\n",
    "#     plt.legend()\n",
    "#     plt.title('Learning Curve: Accuracy')\n",
    "#     plt.savefig(\"accuracy_curve.png\")  # Save accuracy curve\n",
    "#     plt.close()\n",
    "\n",
    "#     print(\"Saved plots as 'loss_curve.png' and 'accuracy_curve.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 2.5392, Train Acc: 51.61%, Val Loss: 3.9644, Val Acc: 19.72%\n",
      "Epoch 2/100, Train Loss: 1.3844, Train Acc: 85.19%, Val Loss: 2.1858, Val Acc: 59.95%\n",
      "Epoch 3/100, Train Loss: 1.2027, Train Acc: 91.01%, Val Loss: 1.5201, Val Acc: 82.05%\n",
      "Epoch 4/100, Train Loss: 1.1140, Train Acc: 93.54%, Val Loss: 1.3009, Val Acc: 86.57%\n",
      "Epoch 5/100, Train Loss: 1.0575, Train Acc: 95.28%, Val Loss: 1.2415, Val Acc: 88.71%\n",
      "Epoch 6/100, Train Loss: 1.0285, Train Acc: 95.88%, Val Loss: 1.2788, Val Acc: 87.42%\n",
      "Epoch 7/100, Train Loss: 0.9895, Train Acc: 97.36%, Val Loss: 1.2233, Val Acc: 88.64%\n",
      "Epoch 8/100, Train Loss: 0.9616, Train Acc: 97.89%, Val Loss: 1.1925, Val Acc: 89.19%\n",
      "Epoch 9/100, Train Loss: 0.9530, Train Acc: 97.85%, Val Loss: 1.1299, Val Acc: 92.43%\n",
      "Epoch 10/100, Train Loss: 0.9409, Train Acc: 98.14%, Val Loss: 1.2208, Val Acc: 88.10%\n",
      "Epoch 11/100, Train Loss: 0.9443, Train Acc: 98.12%, Val Loss: 1.0885, Val Acc: 92.61%\n",
      "Epoch 12/100, Train Loss: 0.9418, Train Acc: 98.03%, Val Loss: 1.1110, Val Acc: 92.12%\n",
      "Epoch 13/100, Train Loss: 0.9406, Train Acc: 98.21%, Val Loss: 1.1013, Val Acc: 92.61%\n",
      "Epoch 14/100, Train Loss: 0.9215, Train Acc: 98.58%, Val Loss: 1.1159, Val Acc: 92.12%\n",
      "Epoch 15/100, Train Loss: 0.9137, Train Acc: 98.58%, Val Loss: 1.0906, Val Acc: 92.25%\n",
      "Epoch 16/100, Train Loss: 0.8774, Train Acc: 99.56%, Val Loss: 0.9944, Val Acc: 95.24%\n",
      "Epoch 17/100, Train Loss: 0.8618, Train Acc: 99.66%, Val Loss: 0.9828, Val Acc: 95.48%\n",
      "Epoch 18/100, Train Loss: 0.8587, Train Acc: 99.53%, Val Loss: 0.9997, Val Acc: 94.69%\n",
      "Epoch 19/100, Train Loss: 0.8557, Train Acc: 99.68%, Val Loss: 0.9945, Val Acc: 95.18%\n",
      "Epoch 20/100, Train Loss: 0.8508, Train Acc: 99.69%, Val Loss: 0.9839, Val Acc: 95.24%\n",
      "Epoch 21/100, Train Loss: 0.8504, Train Acc: 99.65%, Val Loss: 0.9635, Val Acc: 96.15%\n",
      "Epoch 22/100, Train Loss: 0.8466, Train Acc: 99.71%, Val Loss: 0.9797, Val Acc: 95.36%\n",
      "Epoch 23/100, Train Loss: 0.8503, Train Acc: 99.71%, Val Loss: 1.0191, Val Acc: 93.89%\n",
      "Epoch 24/100, Train Loss: 0.8462, Train Acc: 99.68%, Val Loss: 0.9988, Val Acc: 94.87%\n",
      "Epoch 25/100, Train Loss: 0.8389, Train Acc: 99.77%, Val Loss: 0.9804, Val Acc: 95.54%\n",
      "Epoch 26/100, Train Loss: 0.8370, Train Acc: 99.80%, Val Loss: 0.9576, Val Acc: 95.60%\n",
      "Epoch 27/100, Train Loss: 0.8306, Train Acc: 99.82%, Val Loss: 0.9518, Val Acc: 95.60%\n",
      "Epoch 28/100, Train Loss: 0.8281, Train Acc: 99.91%, Val Loss: 0.9461, Val Acc: 95.91%\n",
      "Epoch 29/100, Train Loss: 0.8279, Train Acc: 99.82%, Val Loss: 0.9444, Val Acc: 96.09%\n",
      "Epoch 30/100, Train Loss: 0.8274, Train Acc: 99.85%, Val Loss: 0.9337, Val Acc: 96.40%\n",
      "Epoch 31/100, Train Loss: 0.8245, Train Acc: 99.88%, Val Loss: 0.9283, Val Acc: 96.52%\n",
      "Epoch 32/100, Train Loss: 0.8261, Train Acc: 99.92%, Val Loss: 0.9262, Val Acc: 96.89%\n",
      "Epoch 33/100, Train Loss: 0.8247, Train Acc: 99.94%, Val Loss: 0.9385, Val Acc: 96.21%\n",
      "Epoch 34/100, Train Loss: 0.8230, Train Acc: 99.91%, Val Loss: 0.9460, Val Acc: 95.73%\n",
      "Epoch 35/100, Train Loss: 0.8231, Train Acc: 99.92%, Val Loss: 0.9298, Val Acc: 96.40%\n",
      "Epoch 36/100, Train Loss: 0.8229, Train Acc: 99.89%, Val Loss: 0.9484, Val Acc: 95.67%\n",
      "Epoch 37/100, Train Loss: 0.8174, Train Acc: 99.95%, Val Loss: 0.9312, Val Acc: 96.58%\n",
      "Epoch 38/100, Train Loss: 0.8191, Train Acc: 99.92%, Val Loss: 0.9204, Val Acc: 96.64%\n",
      "Epoch 39/100, Train Loss: 0.8170, Train Acc: 99.92%, Val Loss: 0.9241, Val Acc: 96.83%\n",
      "Epoch 40/100, Train Loss: 0.8180, Train Acc: 99.95%, Val Loss: 0.9188, Val Acc: 96.70%\n",
      "Epoch 41/100, Train Loss: 0.8162, Train Acc: 99.92%, Val Loss: 0.9333, Val Acc: 95.97%\n",
      "Epoch 42/100, Train Loss: 0.8172, Train Acc: 99.89%, Val Loss: 0.9142, Val Acc: 97.07%\n",
      "Epoch 43/100, Train Loss: 0.8163, Train Acc: 99.97%, Val Loss: 0.9097, Val Acc: 97.56%\n",
      "Epoch 44/100, Train Loss: 0.8148, Train Acc: 99.92%, Val Loss: 0.9195, Val Acc: 96.58%\n",
      "Epoch 45/100, Train Loss: 0.8191, Train Acc: 99.94%, Val Loss: 0.9132, Val Acc: 96.95%\n",
      "Epoch 46/100, Train Loss: 0.8161, Train Acc: 99.91%, Val Loss: 0.9282, Val Acc: 96.34%\n",
      "Epoch 47/100, Train Loss: 0.8168, Train Acc: 99.88%, Val Loss: 0.9179, Val Acc: 96.83%\n",
      "Epoch 48/100, Train Loss: 0.8152, Train Acc: 99.95%, Val Loss: 0.9184, Val Acc: 96.76%\n",
      "Epoch 49/100, Train Loss: 0.8152, Train Acc: 99.88%, Val Loss: 0.9158, Val Acc: 96.89%\n",
      "Epoch 50/100, Train Loss: 0.8126, Train Acc: 99.98%, Val Loss: 0.9092, Val Acc: 97.37%\n",
      "Epoch 51/100, Train Loss: 0.8131, Train Acc: 99.97%, Val Loss: 0.9115, Val Acc: 97.07%\n",
      "Epoch 52/100, Train Loss: 0.8135, Train Acc: 99.94%, Val Loss: 0.9226, Val Acc: 96.70%\n",
      "Epoch 53/100, Train Loss: 0.8117, Train Acc: 99.95%, Val Loss: 0.9133, Val Acc: 96.89%\n",
      "Epoch 54/100, Train Loss: 0.8131, Train Acc: 99.95%, Val Loss: 0.9180, Val Acc: 96.89%\n",
      "Epoch 55/100, Train Loss: 0.8114, Train Acc: 99.91%, Val Loss: 0.9028, Val Acc: 97.25%\n",
      "Epoch 56/100, Train Loss: 0.8101, Train Acc: 99.97%, Val Loss: 0.9107, Val Acc: 96.70%\n",
      "Epoch 57/100, Train Loss: 0.8100, Train Acc: 99.94%, Val Loss: 0.9097, Val Acc: 96.95%\n",
      "Epoch 58/100, Train Loss: 0.8103, Train Acc: 99.95%, Val Loss: 0.9082, Val Acc: 97.31%\n",
      "Epoch 59/100, Train Loss: 0.8094, Train Acc: 99.95%, Val Loss: 0.9239, Val Acc: 96.64%\n",
      "Epoch 60/100, Train Loss: 0.8091, Train Acc: 99.97%, Val Loss: 0.9019, Val Acc: 97.37%\n",
      "Epoch 61/100, Train Loss: 0.8084, Train Acc: 99.97%, Val Loss: 0.9091, Val Acc: 96.76%\n",
      "Epoch 62/100, Train Loss: 0.8097, Train Acc: 99.92%, Val Loss: 0.9101, Val Acc: 96.95%\n",
      "Epoch 63/100, Train Loss: 0.8087, Train Acc: 99.92%, Val Loss: 0.9128, Val Acc: 96.64%\n",
      "Epoch 64/100, Train Loss: 0.8094, Train Acc: 99.95%, Val Loss: 0.9096, Val Acc: 97.19%\n",
      "Epoch 65/100, Train Loss: 0.8086, Train Acc: 100.00%, Val Loss: 0.9132, Val Acc: 96.46%\n",
      "Epoch 66/100, Train Loss: 0.8081, Train Acc: 99.97%, Val Loss: 0.9088, Val Acc: 97.37%\n",
      "Epoch 67/100, Train Loss: 0.8075, Train Acc: 99.97%, Val Loss: 0.9113, Val Acc: 96.95%\n",
      "Epoch 68/100, Train Loss: 0.8086, Train Acc: 99.92%, Val Loss: 0.9113, Val Acc: 97.31%\n",
      "Epoch 69/100, Train Loss: 0.8084, Train Acc: 99.95%, Val Loss: 0.9050, Val Acc: 97.19%\n",
      "Epoch 70/100, Train Loss: 0.8080, Train Acc: 100.00%, Val Loss: 0.9095, Val Acc: 96.89%\n",
      "Epoch 71/100, Train Loss: 0.8109, Train Acc: 99.91%, Val Loss: 0.9176, Val Acc: 97.01%\n",
      "Epoch 72/100, Train Loss: 0.8086, Train Acc: 99.92%, Val Loss: 0.9066, Val Acc: 97.01%\n",
      "Epoch 73/100, Train Loss: 0.8075, Train Acc: 99.97%, Val Loss: 0.9091, Val Acc: 97.25%\n",
      "Epoch 74/100, Train Loss: 0.8089, Train Acc: 99.95%, Val Loss: 0.9075, Val Acc: 97.37%\n",
      "Epoch 75/100, Train Loss: 0.8079, Train Acc: 99.98%, Val Loss: 0.9041, Val Acc: 97.25%\n",
      "Epoch 76/100, Train Loss: 0.8080, Train Acc: 99.94%, Val Loss: 0.9092, Val Acc: 97.07%\n",
      "Epoch 77/100, Train Loss: 0.8092, Train Acc: 99.91%, Val Loss: 0.9025, Val Acc: 97.31%\n",
      "Epoch 78/100, Train Loss: 0.8100, Train Acc: 99.97%, Val Loss: 0.8982, Val Acc: 97.37%\n",
      "Epoch 79/100, Train Loss: 0.8073, Train Acc: 99.95%, Val Loss: 0.9264, Val Acc: 97.07%\n",
      "Epoch 80/100, Train Loss: 0.8082, Train Acc: 99.95%, Val Loss: 0.9075, Val Acc: 97.07%\n",
      "Epoch 81/100, Train Loss: 0.8087, Train Acc: 99.95%, Val Loss: 0.9057, Val Acc: 97.25%\n",
      "Epoch 82/100, Train Loss: 0.8072, Train Acc: 99.94%, Val Loss: 0.9103, Val Acc: 97.19%\n",
      "Epoch 83/100, Train Loss: 0.8075, Train Acc: 99.95%, Val Loss: 0.9093, Val Acc: 96.89%\n",
      "Epoch 84/100, Train Loss: 0.8078, Train Acc: 99.98%, Val Loss: 0.9122, Val Acc: 96.58%\n",
      "Epoch 85/100, Train Loss: 0.8073, Train Acc: 99.97%, Val Loss: 0.9047, Val Acc: 97.25%\n",
      "Epoch 86/100, Train Loss: 0.8079, Train Acc: 99.94%, Val Loss: 0.9085, Val Acc: 97.37%\n",
      "Epoch 87/100, Train Loss: 0.8101, Train Acc: 99.95%, Val Loss: 0.9112, Val Acc: 97.07%\n",
      "Epoch 88/100, Train Loss: 0.8080, Train Acc: 99.98%, Val Loss: 0.9049, Val Acc: 96.76%\n",
      "Epoch 89/100, Train Loss: 0.8077, Train Acc: 99.97%, Val Loss: 0.9046, Val Acc: 97.01%\n",
      "Epoch 90/100, Train Loss: 0.8083, Train Acc: 99.95%, Val Loss: 0.9117, Val Acc: 96.89%\n",
      "Epoch 91/100, Train Loss: 0.8088, Train Acc: 99.92%, Val Loss: 0.9082, Val Acc: 97.31%\n",
      "Epoch 92/100, Train Loss: 0.8095, Train Acc: 99.92%, Val Loss: 0.9168, Val Acc: 96.46%\n",
      "Epoch 93/100, Train Loss: 0.8073, Train Acc: 99.95%, Val Loss: 0.8992, Val Acc: 97.56%\n",
      "Epoch 94/100, Train Loss: 0.8085, Train Acc: 99.95%, Val Loss: 0.9015, Val Acc: 97.74%\n",
      "Epoch 95/100, Train Loss: 0.8075, Train Acc: 99.97%, Val Loss: 0.9064, Val Acc: 97.19%\n",
      "Epoch 96/100, Train Loss: 0.8087, Train Acc: 99.98%, Val Loss: 0.9126, Val Acc: 96.95%\n",
      "Epoch 97/100, Train Loss: 0.8092, Train Acc: 99.97%, Val Loss: 0.8986, Val Acc: 97.50%\n",
      "Epoch 98/100, Train Loss: 0.8090, Train Acc: 99.94%, Val Loss: 0.9063, Val Acc: 97.19%\n",
      "Epoch 99/100, Train Loss: 0.8077, Train Acc: 99.98%, Val Loss: 0.8980, Val Acc: 97.56%\n",
      "Epoch 100/100, Train Loss: 0.8081, Train Acc: 99.98%, Val Loss: 0.9100, Val Acc: 97.50%\n",
      "\n",
      "Elapsed time: 2319.40 seconds\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_and_save_curves' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mElapsed time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Plot and save learning curves\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mplot_and_save_curves\u001b[49m(train_losses, val_losses, train_accuracies, val_accuracies)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_and_save_curves' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model, train_losses, val_losses, train_accuracies, val_accuracies, elapsed_time = train_model(\n",
    "    model, criterion, optimizer, train_loader, val_loader, num_epochs=100\n",
    ")\n",
    "\n",
    "print(f\"\\nElapsed time: {elapsed_time:.2f} seconds\\n\")\n",
    "\n",
    "# Plot and save learning curves\n",
    "plot_and_save_curves(train_losses, val_losses, train_accuracies, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (6.0.0)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /usr/local/lib/python3.10/dist-packages (from plotly) (1.26.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (23.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# Show interactive plot\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     fig\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 48\u001b[0m plot_interactive_curves(\u001b[43mtrain_losses\u001b[49m, val_losses, train_accuracies, val_accuracies)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plot_interactive_curves(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "    \"\"\"Plot interactive loss and accuracy curves using Plotly.\"\"\"\n",
    "    \n",
    "    epochs = list(range(1, len(train_losses) + 1))  # X-axis: Epochs\n",
    "\n",
    "    # Create subplot: Loss (row 1) and Accuracy (row 2)\n",
    "    fig = make_subplots(rows=2, cols=1, \n",
    "                        shared_xaxes=True, \n",
    "                        subplot_titles=(\"Loss Curve\", \"Accuracy Curve\"))\n",
    "\n",
    "    # Plot Losses\n",
    "    fig.add_trace(go.Scatter(x=epochs, y=train_losses, mode='lines+markers',\n",
    "                             name='Training Loss', marker=dict(symbol=\"circle\")),\n",
    "                  row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=epochs, y=val_losses, mode='lines+markers',\n",
    "                             name='Validation Loss', marker=dict(symbol=\"square\")),\n",
    "                  row=1, col=1)\n",
    "\n",
    "    # Plot Accuracies\n",
    "    fig.add_trace(go.Scatter(x=epochs, y=train_accuracies, mode='lines+markers',\n",
    "                             name='Training Accuracy', marker=dict(symbol=\"circle\")),\n",
    "                  row=2, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=epochs, y=val_accuracies, mode='lines+markers',\n",
    "                             name='Validation Accuracy', marker=dict(symbol=\"square\")),\n",
    "                  row=2, col=1)\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=900,  # Increase height\n",
    "        width=1200,  # Increase width\n",
    "        title_text=\"Training Progress\",\n",
    "        xaxis2=dict(title=\"Epochs\"),\n",
    "        yaxis=dict(title=\"Loss\"),\n",
    "        yaxis2=dict(title=\"Accuracy (%)\"),\n",
    "    )\n",
    "\n",
    "    # Save plot as image (PNG)\n",
    "    fig.write_image(\"training_progress.png\")\n",
    "    \n",
    "    # Show interactive plot\n",
    "    fig.show()\n",
    "\n",
    "plot_interactive_curves(train_losses, val_losses, train_accuracies, val_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract best accuracy and corresponding epoch\n",
    "best_train_acc = max(train_accuracies)\n",
    "best_train_acc_epoch = np.argmax(train_accuracies) + 1\n",
    "\n",
    "best_val_acc = max(val_accuracies)\n",
    "best_val_acc_epoch = np.argmax(val_accuracies) + 1\n",
    "\n",
    "# Extract best (lowest) loss and corresponding epoch\n",
    "best_train_loss = min(train_losses)\n",
    "best_train_loss_epoch = np.argmin(train_losses) + 1\n",
    "\n",
    "best_val_loss = min(val_losses)\n",
    "best_val_loss_epoch = np.argmin(val_losses) + 1\n",
    "\n",
    "# Create a summary dictionary\n",
    "best_metrics_summary = {\n",
    "    \"Metric\": [\"Best Training Accuracy\", \"Best Validation Accuracy\", \"Best Training Loss\", \"Best Validation Loss\"],\n",
    "    \"Value\": [f\"{best_train_acc:.2f}%\", f\"{best_val_acc:.2f}%\", f\"{best_train_loss:.4f}\", f\"{best_val_loss:.4f}\"],\n",
    "    \"Epoch\": [best_train_acc_epoch, best_val_acc_epoch, best_train_loss_epoch, best_val_loss_epoch]\n",
    "}\n",
    "\n",
    "# Convert to dataframe and display\n",
    "import pandas as pd\n",
    "best_metrics_df = pd.DataFrame(best_metrics_summary)\n",
    "\n",
    "best_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
